library(xgboost)
install.packages("xgboost")
library(xgboost)
?xgboost
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
lettersdf <- read.csv("data/lettersdf.csv", header = T)
#Note: we can't use our typical rsample
#method since some observations are duplicates
set.seed(1)
train_index <- sample(1:nrow(lettersdf), nrow(lettersdf) * .75)
test_index <- (1:nrow(lettersdf))[-(train_index)]
letters_trn<-lettersdf %>% slice(train_index)
letters_tst<-lettersdf %>% slice(test_index)
##apply the following function to the output of predict()
my_predictions <- function(x){ LETTERS[apply(x, 1, which.max)]}
xboost_letters <- xgboost(
data = letters_trn,
label = letters_trn$V1,
max_depth = 1,
objective = "multi:softmax"
)
xboost_letters <- xgboost(
data = letters_trn,
label = letters_trn$V1,
max_depth = 1,
objective = "multi:softmax",
num_class = 26
)
